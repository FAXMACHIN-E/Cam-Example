{% extends "layout.html" %} 

{% block styles %} 
{% endblock %} 

{% block scripts %}
<!-- <script type="text/javascript" src="https://d3js.org/d3.v7.min.js"></script> -->

{% endblock %} 

{% block content %} 
<header>
    <div class="container"> 
        <h1>Image based ASL Interpretor Web Application </h1>
        <br>
        <h2><li>Goals</li></h2>
        <h4>Ideal Use Case (Long Term)</h4>
          <p>
              To build an image recognization Web App to help deaf & mute people 
              communicate, using American Sign Language (ASL), with those who doesn't know ASL. 
              The App will accept input from both live-stream and video upload.
          </p>
          <p> 
              Why is this useful? While we can ask deaf & mute people to type, 
              it'd be greatly useful if they don't touch keyboards 
              in the middle of a presentation going through slides or 
              annotating on a whiteboard.
          </p>
        <h4>MVP (Now)</h4>
        <p>
          To build an image recognization Web App to predict the English letters
          based on the uploaded static IMAGE containing relevant ASL signs.
        </p>
        <h4>Final Project Plan (by the End of the Summer)</h4>
        <p>
          To build an image recognization Web App to predict the English letters
          based on the VIDEO containing relevant ASL signs. The App will 
          accept input from live-stream, video upload or both.
        </p>
        <p>
          We plan to have per account login available and the users will be able
          to see history and other information of themselves.
        </p>
        <br><br>
        <h2><li>Illustration of A Similar Working Example</li></h2>
        <p> 
          We'll provide web interface for users to upload files or connect with 
          their PC's cameras. For each of the frames in the video, we interpret 
          the American Sign Language gesture into an English letter 
          (or words and phrases in the future).
        </p>
        <p>
          <img src="https://blog.roboflow.com/content/images/2020/10/alphabet-intro.gif" 
            alt="Example Image" class="ratio" style="max-width: 640px">
        </p>
        <p>
          <cite>GIF from </cite>
          <a style="font-size:15px" href="https://public.roboflow.com/object-detection/american-sign-language-letters">
            Roboflow - American Sign Language Letters Dataset
          </a>
        </p>
        <br><br>
        <h2><li>How Does the Back End Model Work?</li></h2>
        <p> 
          We first use mediapipe library to parse images to 3D hand landmarks and 
          then use our self-trained multi-label classifier to predict the letter 
          using the landmarks as the model input.
        </p>
        <br><br>
        <h2><li>Major Items Missing for the Final Project Delivery</li></h2>
        <p> 
          <ol>
          <li>Video streaming or video upload</li>
          <li>Login/Security</li>
          </ol>
        </p>
        <br><br>
        <h2><li>Background of American Sign Language (ASL)</li></h2>
        <p>
            <a style="font-size:15px" href="https://en.wikipedia.org/wiki/American_Sign_Language">Wikipedia - American Sign Language</a>
        </p>
        <p>
          <img alt="American Sign Language ASL.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/7/7d/American_Sign_Language_ASL.svg/250px-American_Sign_Language_ASL.svg.png" decoding="async" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/7/7d/American_Sign_Language_ASL.svg/375px-American_Sign_Language_ASL.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/7d/American_Sign_Language_ASL.svg/500px-American_Sign_Language_ASL.svg.png 2x" data-file-width="512" data-file-height="231" width="250" height="113">
        </p>
    </div>
</header>
<div class="slide">
    <div id="vis1" class="vis"></div>
    <!--div id="vis2" class="vis"></div>
    <div id="vis3" class="vis"></div-->
</div>

{% endblock %}
